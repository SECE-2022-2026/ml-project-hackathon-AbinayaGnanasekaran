# -*- coding: utf-8 -*-
"""Product recommendation system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NOJIIDIITVJL5hbBAE-_scIOvz8Rjy00
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import precision_score, recall_score
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.sequence import pad_sequences
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
data = pd.read_csv('/content/data.csv', encoding='latin1')
print(data.head())

data = data.dropna(subset=['CustomerID', 'StockCode'])
user_encoder = LabelEncoder()
data['CustomerID'] = user_encoder.fit_transform(data['CustomerID'])

product_encoder = LabelEncoder()
data['StockCode'] = product_encoder.fit_transform(data['StockCode'])

data['InvoiceNo'] = data['InvoiceNo'].astype(str)
sessions = data.groupby('InvoiceNo')['StockCode'].apply(list).reset_index()
print(sessions.head())



data = data.dropna(subset=['CustomerID', 'StockCode'])

user_encoder = LabelEncoder()
data['CustomerID'] = user_encoder.fit_transform(data['CustomerID'])

product_encoder = LabelEncoder()
data['StockCode'] = product_encoder.fit_transform(data['StockCode'])
data['InvoiceNo'] = data['InvoiceNo'].astype(str)
sessions = data.groupby('InvoiceNo')['StockCode'].apply(list).reset_index()
print(sessions.head())

from gensim.models import Word2Vec
w2v_model = Word2Vec(sentences=sessions['StockCode'], vector_size=50, window=5, min_count=1, workers=4)
product_vector = w2v_model.wv[0]  # Replace 0 with an actual product ID
print(product_vector)

X = []
y = []

for session in sessions['StockCode']:
    for i in range(1, len(session)):
        X.append(session[:i])  # Input sequence
        y.append(session[i])   # Next product
X = pad_sequences(X, maxlen=10, padding='pre')
y = np.array(y)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

num_products = len(product_encoder.classes_)
embedding_dim = 50
model = Sequential([
    Embedding(input_dim=num_products, output_dim=embedding_dim, input_length=10),
    LSTM(128, return_sequences=False),
    Dense(num_products, activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()

history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

from transformers import pipeline
sentiment_pipeline = pipeline("sentiment-analysis")
sample_reviews = data['Description'][:5].tolist()
sentiments = sentiment_pipeline(sample_reviews)
print(sentiments)

def boost_product_score(product_id, sentiment_score):
    base_score = product_rankings[product_id]
    boosted_score = base_score + sentiment_score
    return boosted_score

print(data.columns)

# Create the interaction matrix based on Quantity
interaction_matrix = data.pivot_table(index='CustomerID', columns='StockCode', values='Quantity', fill_value=0)

# Check the shape of the interaction matrix
print(interaction_matrix.shape)

def adjust_recommendation_with_sentiment(product_id, sentiment_score):
    base_score = product_rankings[product_id]
    return base_score + sentiment_score

sample_input = X_test[0].reshape(1, -1)
predicted = model.predict(sample_input)
predicted_product = np.argmax(predicted)

print("Predicted Product:", product_encoder.inverse_transform([predicted_product]))

from sklearn.metrics import accuracy_score
y_pred = np.argmax(model.predict(X_test), axis=1)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()



def boost_product_score(product_id, sentiment_score):
    base_score = product_rankings[product_id]
    boosted_score = base_score + sentiment_score
    return boosted_score

print(data.columns)
data['interaction'] = 1  # Assuming every row represents an interaction (e.g., view or purchase)
interaction_matrix = data.pivot_table(index='CustomerID', columns='StockCode', values='interaction', fill_value=0)
interaction_matrix = data.pivot_table(index='CustomerID', columns='StockCode', values='interaction', fill_value=0)
print(interaction_matrix)

from sklearn.metrics.pairwise import cosine_similarity
user_similarity = cosine_similarity(interaction_matrix)
print(user_similarity)

interaction_matrix = data.pivot_table(index='CustomerID',
                                      columns='StockCode',
                                      values='Quantity',
                                      fill_value=0)

from sklearn.metrics.pairwise import cosine_similarity

user_similarity = cosine_similarity(interaction_matrix)

def recommend_products(user_id, interaction_matrix, user_similarity, top_n=5):
    user_interactions = interaction_matrix.iloc[user_id].values
    similar_users = user_similarity[user_id]

    product_scores = similar_users @ interaction_matrix.values

    product_scores[user_interactions > 0] = 0

    recommended_indices = product_scores.argsort()[::-1][:top_n]
    recommended_products = interaction_matrix.columns[recommended_indices]
    return recommended_products

def recommend_products(user_id, interaction_matrix, user_similarity, top_n=5):

    similar_users = user_similarity[user_id]
    weighted_interactions = interaction_matrix.T.dot(similar_users)
    recommended_products = weighted_interactions.argsort()[-top_n:][::-1]
    product_names = interaction_matrix.columns[recommended_products]

    return product_names
user_id = 0
recommended_products = recommend_products(user_id, interaction_matrix, user_similarity, top_n=5)
print(f"Recommended products for User {user_id}: {recommended_products}")

def precision_at_k(actual, predicted, k):
    actual_set = set(actual[:k])
    predicted_set = set(predicted[:k])
    return len(actual_set & predicted_set) / len(predicted_set)
precision = precision_at_k([1, 2, 3], [2, 3, 4], k=2)
print("Precision@K:", precision)

def adjust_recommendation_with_sentiment(product_id, sentiment_score):
    base_score = product_rankings[product_id]
    return base_score + sentiment_score

sample_input = X_test[0].reshape(1, -1)
predicted = model.predict(sample_input)
predicted_product = np.argmax(predicted)

print("Predicted Product:", product_encoder.inverse_transform([predicted_product]))

from sklearn.metrics import accuracy_score
y_pred = np.argmax(model.predict(X_test), axis=1)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

pip install kafka-python

from kafka import KafkaProducer